{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfea44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This notebook generates pertubed datasets for statistical method.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ed251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from utils.encode_datasets import read_and_encode_dataset\n",
    "\n",
    "from pure_ldp.frequency_oracles.local_hashing import LHClient, LHServer\n",
    "from pure_ldp.frequency_oracles.unary_encoding import UEClient, UEServer\n",
    "from mechanisms.exponential.exponential_mechanism import Exponential_mechanism\n",
    "\n",
    "from pure_frequency_oracles.GRR import GRR_Client, GRR_Aggregator_MI\n",
    "from pure_frequency_oracles.SS import SS_Client, SS_Aggregator_MI\n",
    "from pure_frequency_oracles.HE import HE_Client, HE_Aggregator_MI\n",
    "from privacy_leakage.attackers import attack_lh, attack_ss, attack_ue, attack_she"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROCESS = 1\n",
    "\n",
    "EPS_ARRAY = [1, 2]\n",
    "\n",
    "def exp_aggregator(reports, k):\n",
    "    freq_array = np.zeros(k)\n",
    "\n",
    "    for i in reports:\n",
    "        freq_array[i] += 1\n",
    "    \n",
    "    return freq_array\n",
    "\n",
    "def data_generator(parameter):\n",
    "    attribute_name, eps, repetitions, mechanism = parameter\n",
    "    data_values = data[attribute_name].values\n",
    "    alphabet = np.sort(np.unique(data_values))\n",
    "    state_count = len(alphabet)\n",
    "    states = list(alphabet)\n",
    "    sample_count = len(data_values)\n",
    "    d = state_count\n",
    "\n",
    "    if mechanism == 'olh':\n",
    "        client = LHClient(epsilon=eps, d=d, use_olh=True)\n",
    "        server = LHServer(epsilon=eps, d=d, use_olh=True)\n",
    "        g = int(np.round(np.exp(eps))) + 1\n",
    "    elif mechanism == 'blh':\n",
    "        client = LHClient(epsilon=eps, d=d, use_olh=False)\n",
    "        server = LHServer(epsilon=eps, d=d, use_olh=False)\n",
    "        g = 2\n",
    "    elif mechanism == 'oue':\n",
    "        client = UEClient(epsilon=eps, d=d, use_oue=True)\n",
    "        server = UEServer(epsilon=eps, d=d, use_oue=True)\n",
    "    elif mechanism == 'rappor':\n",
    "        client = UEClient(epsilon=eps, d=d, use_oue=False)\n",
    "        server = UEServer(epsilon=eps, d=d, use_oue=False)\n",
    "    elif mechanism == 'exp':\n",
    "        prior_dist = np.ones((state_count))/state_count\n",
    "        error_matrix = np.ones((state_count, state_count)) - np.identity(state_count)\n",
    "        client = Exponential_mechanism(STATE_COUNT=state_count, INPUT_ALPHABET=states, prior_dist=prior_dist, normalized_objective_err_matrix=error_matrix)\n",
    "\n",
    "    output_list = []\n",
    "    attack_output_list = []\n",
    "\n",
    "    is_computed_utility = False\n",
    "\n",
    "    actual_freq = []\n",
    "    estimated_freq = []\n",
    "\n",
    "    for j in range(repetitions):\n",
    "        for i in range(len(data_values)):\n",
    "            \n",
    "            if mechanism == 'olh' or mechanism == 'blh':\n",
    "                priv_data = client.privatise(data_values[i]+1)\n",
    "                perturbed_output = priv_data[0]\n",
    "                output_list.append(perturbed_output)\n",
    "                server.aggregate(priv_data)\n",
    "                attack_output_list.append(attack_lh(val_seed=priv_data, k=d, g=g))\n",
    "\n",
    "            elif mechanism == 'oue' or mechanism == 'rappor':\n",
    "                priv_data = client.privatise(data_values[i]+1)\n",
    "                output_list.append(priv_data)\n",
    "                server.aggregate(priv_data)\n",
    "                attack_output_list.append(attack_ue(ue_val=priv_data, k=d))\n",
    "\n",
    "            elif mechanism == 'grr':\n",
    "                priv_data = GRR_Client(input_data=data_values[i], k=d, epsilon=eps) \n",
    "                output_list.append(priv_data)\n",
    "                attack_output_list.append(priv_data)\n",
    "\n",
    "            elif mechanism == 'ss':\n",
    "                priv_data = SS_Client(input_data=data_values[i], k=d, epsilon=eps)\n",
    "                output_list.append(priv_data)\n",
    "                attack_output_list.append(attack_ss(priv_data))\n",
    "\n",
    "            elif mechanism == 'she':\n",
    "                priv_data = HE_Client(input_data=data_values[i], k=d, epsilon=eps)\n",
    "                output_list.append(priv_data)\n",
    "                attack_output_list.append(attack_she(y=priv_data, k=d, epsilon=eps))\n",
    "\n",
    "            elif mechanism == 'exp':\n",
    "                priv_data = client.gen_random_output(actual_value=data_values[i], eps=eps)[0]\n",
    "                output_list.append(priv_data)\n",
    "                attack_output_list.append(priv_data)\n",
    "\n",
    "        if not(is_computed_utility):\n",
    "            if mechanism == \"grr\":\n",
    "                estimated_freq = list(GRR_Aggregator_MI(reports=output_list, k=d, epsilon=eps)*sample_count)\n",
    "            elif mechanism == \"she\":\n",
    "                estimated_freq = list(HE_Aggregator_MI(reports=output_list, k=d, epsilon=eps, use_thresh=False)*sample_count)\n",
    "            elif mechanism == \"ss\":\n",
    "                estimated_freq = list(SS_Aggregator_MI(reports=output_list, k=d, epsilon=eps)*sample_count)\n",
    "            elif mechanism == \"exp\":\n",
    "                estimated_freq = list(exp_aggregator(reports=output_list, k=d))\n",
    "\n",
    "            for val in states:\n",
    "                if mechanism == \"olh\" or mechanism == \"blh\" or mechanism == \"oue\" or mechanism == \"rappor\":\n",
    "                    estimated_freq.append(server.estimate(val+1))\n",
    "\n",
    "                count_ = 0\n",
    "                for data_i in data_values:\n",
    "                    if (data_i) == (val):\n",
    "                        count_ += 1\n",
    "                actual_freq.append(count_)    \n",
    "\n",
    "        is_computed_utility = True\n",
    "    \n",
    "    return output_list, attribute_name, actual_freq, estimated_freq, attack_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "datasets = ['celeba']\n",
    "num_repititions = {'celeba': r}\n",
    "mechanisms = [\"grr\"]\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    \n",
    "    data, COLUMNS = read_and_encode_dataset(dataset_name=dataset_name)\n",
    "    NUM_REPITTIONS = num_repititions[dataset_name]\n",
    "    NUM_ATTRIBUTES = len(COLUMNS)\n",
    "\n",
    "    for mechanism in mechanisms:\n",
    "        file_location = f\"perturbed_datasets_benchmark/{dataset_name}/{mechanism}\"\n",
    "        list_available_files = os.listdir(file_location)\n",
    "\n",
    "        for eps in EPS_ARRAY:\n",
    "            final_perturbed_data_list = []\n",
    "            actual_frequencies_list = []\n",
    "            estimated_frequencies_list = []\n",
    "            last_index = 0\n",
    "            attack_output_list = []\n",
    "\n",
    "            while last_index < NUM_ATTRIBUTES:\n",
    "                sub_attribute_list = [] \n",
    "                for i in range(NUM_PROCESS):\n",
    "                    actual_index = last_index + i\n",
    "                    if actual_index >= NUM_ATTRIBUTES:\n",
    "                        break\n",
    "                    sub_attribute_list.append(COLUMNS[actual_index])\n",
    "\n",
    "                num_processes = min(NUM_PROCESS, len(sub_attribute_list))\n",
    "\n",
    "                with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "                    futures = [executor.submit(data_generator, (sub_attribute_list[j], eps, NUM_REPITTIONS, mechanism)) for j in range(num_processes)]\n",
    "                    results_ = [future.result() for future in futures]\n",
    "\n",
    "                for k in sub_attribute_list:\n",
    "                    for r in results_:\n",
    "                        if r[1] == k:\n",
    "                            attack_output_list.append(r[4])\n",
    "                            final_perturbed_data_list.append(r[0])\n",
    "                            actual_frequencies_list.append(r[2])\n",
    "                            estimated_frequencies_list.append(r[3])\n",
    "                            break\n",
    "                last_index += len(sub_attribute_list)\n",
    "            attack_output_list = np.transpose(np.array(attack_output_list))\n",
    "\n",
    "            data_frame2 = pd.DataFrame(attack_output_list, columns=COLUMNS)\n",
    "            data_frame2.to_csv(f'{file_location}/attack_{eps}.csv.zip', compression='zip', index=False)\n",
    "            with open(f'{file_location}/{eps}_freq.pkl', 'wb') as file:\n",
    "                pickle.dump({\"actual_frequencies_list\": actual_frequencies_list, \"estimated_frequencies_list\": estimated_frequencies_list}, file)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
