{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This notebook generates conditional proabability distributions for given datasets.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from utils.encode_datasets import read_and_encode_dataset\n",
    "from utils.util_functions import list_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_alphabet_list(alphabet_list, base_string = \"\", output_list = []):\n",
    "\n",
    "    if len(alphabet_list) == 1:\n",
    "        for i in alphabet_list[0]:\n",
    "            if base_string == \"\":\n",
    "                output_list.append(str(i))\n",
    "            else:\n",
    "                output_list.append(base_string + \" \" + str(i))\n",
    "        return output_list\n",
    "    new_output_list = output_list\n",
    "    new_base_string = base_string\n",
    "\n",
    "    for i in alphabet_list[0]:\n",
    "        if base_string == \"\":\n",
    "            new_base_string = str(i)\n",
    "        else:\n",
    "            new_base_string = base_string + \" \" + str(i)\n",
    "        new_output_list = get_final_alphabet_list(alphabet_list[1:], base_string = new_base_string, output_list = new_output_list)\n",
    "        \n",
    "    return new_output_list\n",
    "\n",
    "def get_ordered_alphabet_(attributes):\n",
    "    alphabet_list = []\n",
    "\n",
    "    if not(isinstance(attributes, list)):\n",
    "        attributes = [attributes]\n",
    "\n",
    "    for i in attributes:\n",
    "        alphabet_list.append(get_ordered_alphabet_individual(i))\n",
    "    return (get_final_alphabet_list(alphabet_list=alphabet_list, base_string = \"\", output_list = []))\n",
    "        \n",
    "def get_ordered_alphabet_individual(attribute):\n",
    "    return (np.unique(original_data[attribute].values))\n",
    "\n",
    "def ignore_nan(arr):\n",
    "    return max(filter(lambda x: not (math.isinf(x) or math.isnan(x)), arr))\n",
    "\n",
    "def get_CMF(filtered_original_data, filtered_perturb_data, Z_alphabet, X_k_alphabet, samples):\n",
    "    probability_matrix = np.ones((len(X_k_alphabet), len(Z_alphabet)))\n",
    "    len_of_original_dataset = np.shape(filtered_original_data)[0]\n",
    "\n",
    "    index_x_k = 0\n",
    "    index_z = 0\n",
    "    \n",
    "    for index_i, i in enumerate(filtered_perturb_data[:samples,:]):\n",
    "        index_z = Z_alphabet.index(list_to_string(i)[:-1])\n",
    "        index_x_k = X_k_alphabet.index(list_to_string(filtered_original_data[index_i%len_of_original_dataset])[:-1])\n",
    "        probability_matrix[index_x_k][index_z] += 1\n",
    "\n",
    "    for i in range(np.shape(probability_matrix)[0]):\n",
    "        for j in range(np.shape(probability_matrix)[1]):\n",
    "            if probability_matrix[i][j] < 3:\n",
    "                probability_matrix[i][j] = 0\n",
    "\n",
    "    probability_matrix /= np.sum(probability_matrix)\n",
    "    conditional_matrix = np.transpose(np.transpose(probability_matrix)/np.sum(probability_matrix, axis=1))\n",
    "\n",
    "    return conditional_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"celeba\"] # ['adult', 'cardio', 'celeba', 'SPM_2016', 'dss'] #SPM-2023\n",
    "\n",
    "file_location = '/datasets/celeba.txt'\n",
    "\n",
    "def validate(cmf, column):\n",
    "    for index_i, i in enumerate(column[:]):\n",
    "        for index_j, j in enumerate(column):\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            key_ = str(i) + ' ' + str(j)\n",
    "                \n",
    "            if key_ not in cmf.keys():\n",
    "                print(\"Incomplete CMF\")\n",
    "                raise ValueError(f\"Error key {index_i}, {index_j}\")\n",
    "                \n",
    "def read_csv(name):\n",
    "    original_data, COLUMNS = read_and_encode_dataset(dataset_name=name)\n",
    "    return original_data\n",
    "\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        with open(f'{file_location}/{dataset}/{dataset}_cmf.pkl', 'rb') as file:\n",
    "            CMF_dict, COLUMNS = pickle.load(file)\n",
    "            validate(CMF_dict, COLUMNS)\n",
    "    except:\n",
    "        original_data = read_csv(dataset)\n",
    "\n",
    "        COLUMNS = original_data.columns\n",
    "        try:\n",
    "            with open(f'{file_location}/{dataset}/{dataset}_cmf.pkl', 'rb') as file:\n",
    "                CMF_dict, _ = pickle.load(file)\n",
    "        except:\n",
    "            CMF_dict = {}\n",
    "        \n",
    "        for index_i, i in enumerate(COLUMNS[:]):\n",
    "            for index_j, j in enumerate(COLUMNS):\n",
    "\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                X_k = [i]\n",
    "                Z = [j]\n",
    "                \n",
    "                X_k_alphabet = get_ordered_alphabet_(X_k)\n",
    "                Z_alphabet = get_ordered_alphabet_(Z)\n",
    "\n",
    "                filtered_original_data = original_data[X_k].values\n",
    "                filtered_perturb_data = original_data[Z].values\n",
    "\n",
    "                key_ = str(i) + ' ' + str(j)\n",
    "                print(\"key \", index_i, index_j)\n",
    "                if key_ not in CMF_dict.keys():\n",
    "                    CMF = get_CMF(filtered_original_data, filtered_perturb_data, Z_alphabet, X_k_alphabet, samples=original_data.shape[0])\n",
    "                    CMF_dict[key_] = CMF\n",
    "\n",
    "            with open(f'{file_location}/{dataset}_cmf.pkl', 'wb') as file:\n",
    "                pickle.dump((CMF_dict, COLUMNS), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
